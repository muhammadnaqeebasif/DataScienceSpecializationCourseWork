}
g_plots_list <- list()
for(i in 1:8){
g <- createPlotByColour(training,"CompressiveStrength",colour= cut2(training[,i],g=4),title=colnames(training)[i])
g_plots_list<-list.append(g_plots_list,g)
}
grid.arrange(grobs=g_plots_list,ncol=2)
g_plots_list[1]
g_plots_list[2]
library(ggplot2)
library(Hmisc)
library(rlist)
createPlotByColour <- function(data,colour,pred=NA,title){
if(is.na(pred)){
pred <- 1:dim(data)[1]
}
g <- ggplot(data=data,aes(x=pred,y=CompressiveStrength,colour=colour))+
geom_point() + labs(title=title)
g
}
g_plots_list <- list()
for(i in 1:8){
colour <- colour= cut2(training[,i],g=4)
g <- createPlotByColour(training,"",colour=colour ,title=colnames(training)[i])
g_plots_list<-list.append(g_plots_list,g)
}
library(ggplot2)
library(Hmisc)
library(rlist)
createPlotByColour <- function(data,colour,pred=NA,title){
if(is.na(pred)){
pred <- 1:dim(data)[1]
}
g <- ggplot(data=data,aes(x=pred,y=CompressiveStrength,colour=colour))+
geom_point() + labs(title=title)
g
}
g_plots_list <- list()
for(i in 1:8){
colour <- cut2(training[,i],g=4)
g <- createPlotByColour(training,"",colour=colour ,title=colnames(training)[i])
g_plots_list<-list.append(g_plots_list,g)
}
grid.arrange(grobs=g_plots_list,ncol=2)
createPlotByColour(training,colour= cut2(training[,1],g=4),title=colnames(training)[1])
createPlotByColour(training,colour= cut2(training[,2],g=4),title=colnames(training)[2])
createPlotByColour(training,colour= cut2(training[,3],g=4),title=colnames(training)[3])
createPlotByColour(training,colour= cut2(training[,4],g=4),title=colnames(training)[4])
createPlotByColour(training,colour= cut2(training[,5],g=4),title=colnames(training)[5])
createPlotByColour(training,colour= cut2(training[,6],g=4),title=colnames(training)[6])
createPlotByColour(training,colour= cut2(training[,7],g=4),title=colnames(training)[7])
createPlotByColour(training,colour= cut2(training[,8],g=4),title=colnames(training)[8])
createPlotByColour(training,colour= cut2(training[,9],g=4),title=colnames(training)[9])
library(AppliedPredictiveModeling)
data(concrete)
library(caret)
set.seed(1000)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
qplot(SuperPlasticizer,data = training)
head(training)
library(AppliedPredictiveModeling)
data(concrete)
library(caret)
set.seed(1000)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
qplot(Superplasticizer,data = training)
qplot(log10(Superplasticizer+1),data = training)
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
head(testing)
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
trainingIL <- training[,grep("^IL", names(training))]
procTrain <- preProcess(trainingIL, method = "pca", thresh = 0.9 )
procTrain
str(training)
trainingIL <- training[,grep("^IL|diagnosis", names(training))]
head(trainingIL)
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
trainingIL <- training[,grep("^IL", names(training))]
testingIL <- training[,grep("^IL", names(testing))]
model_notPC <- train(training$diagnosis~.,method="glm",data=trainingIL)
trainingIL
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
trainingIL <- training[,grep("^IL|diagnosis", names(training))]
testingIL <- training[,grep("^IL|diagnosis", names(testing))]
model_notPC <- train(diagnosis ~.,method="glm",data=trainingIL)
confusionMatrix(testing$diagnosis,predict(model_notPC,testingIL))
testingIL$diagnosis
confusionMatrix(testingIL$diagnosis,predict(model_notPC,testingIL))
model_notPC <- train(diagnosis ~.,method="glm",preprocess="pca",thresh = 0.8,data=trainingIL)
model_notPC <- train(diagnosis ~.,method="glm",preprocess="pca",data=trainingIL)
model_notPC <- train(diagnosis ~.,method="glm",preProcess="pca",data=trainingIL)
confusionMatrix(testingIL$diagnosis,predict(model_notPC,testingIL))
model_notPC <- train(diagnosis ~.,method="glm",preProcess="pca",thresh=0.8,data=trainingIL)
ctrl <- trainControl(preProcOptions = list(thresh = 0.8))
model_notPC <- train(diagnosis ~.,method="glm",preProcess="pca",trControl=ctrl,data=trainingIL)
confusionMatrix(testingIL$diagnosis,predict(model_notPC,testingIL))
model <- train(diagnosis ~ ., data = trainingIL, method = "glm")
predict_model <- predict(model, newdata= testingIL)
matrix_model <- confusionMatrix(predict_model, testingIL$diagnosis)
matrix_model$overall[1]
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
# grep all columns with IL and diagnosis in the traning and testing set
trainingIL <- training[,grep("^IL|diagnosis", names(training))]
testingIL <- testing[,grep("^IL|diagnosis", names(testing))]
# non-PCA
model <- train(diagnosis ~ ., data = trainingIL, method = "glm")
predict_model <- predict(model, newdata= testingIL)
matrix_model <- confusionMatrix(predict_model, testingIL$diagnosis)
matrix_model$overall[1]
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
trainingIL <- training[,grep("^IL|diagnosis", names(training))]
testingIL <- training[,grep("^IL|diagnosis", names(testing))]
model_notPC <- train(diagnosis ~.,method="glm",data=trainingIL)
mat <-confusionMatrix(testingIL$diagnosis,predict(model_notPC,testingIL))
mat$overall[1]
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
trainingIL <- training[,grep("^IL|diagnosis", names(training))]
testingIL <- training[,grep("^IL|diagnosis", names(testing))]
model_notPC <- train(diagnosis ~.,method="glm",data=trainingIL)
mat <-confusionMatrix(testingIL$diagnosis,predict(model_notPC,newdata=testingIL))
mat$overall[1]
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
trainingIL <- training[,grep("^IL|diagnosis", names(training))]
testingIL <- testing[,grep("^IL|diagnosis", names(testing))]
model_notPC <- train(diagnosis ~.,method="glm",data=trainingIL)
mat <-confusionMatrix(testingIL$diagnosis,predict(model_notPC,newdata=testingIL))
mat$overall[1]
ctrl <- trainControl(preProcOptions = list(thresh = 0.8))
model_notPC <- train(diagnosis ~.,method="glm",preProcess="pca",trControl=ctrl,data=trainingIL)
confusionMatrix(testingIL$diagnosis,predict(model_notPC,testingIL))
install.packages("ElemStatLearn")
library(ElemStatLearn);data(ozone,package = "ElemStatLearn")
library(ElemStatLearn);data(ozone,package = "ElemStatLearn")
ozone <- ozone[order(ozone$ozone)]
library(ElemStatLearn);data(ozone,package = "ElemStatLearn")
ozone <- ozone[order(ozone$ozone),]
head(ozone)
library(ElemStatLearn);data(ozone,package = "ElemStatLearn")
ozone <- ozone[order(ozone$ozone),]
head(ozone)
predict(modFit,newdata = testing)
data("iris");library(ggplot2)
names(iris)
table(iris$Species)
library(caret)
inTrain <- createDataPartition(y=iris$Species,p=0.7,list=F)#
training <- iris[inTrain,]
testing <- iris[-inTrain,]
dim(training);dim(testing)
g <- ggplot(data=training,aes(x=Petal.Width,y=Sepal.Width,colour=Species))
g +geom_point()
library(caret)
modFit <- train(Species~.,method="rpart",data=training)
print(modFit$finalModel)
plot(modFit$finalModel,uniform = TRUE)
text(modFit$finalModel,use.n = TRUE,all=TRUE)
library(rattle)
fancyRpartPlot(modFit$finalModel)
predict(modFit,newdata = testing)
ll <- matrix(NA,nrow = 10,ncol=155)
for(i in 1:10){
ss <- sample(1:dim(ozone)[1],replace = T)
ozone0 <- ozone[ss,];ozone0 <-ozone0[order(ozone0$ozone),]
loess0 <- loess(temperature ~ ozone,data=ozone0,span=0.2)
ll[i,] <- predict(loess0,newdata=data.frame(ozone=1:155))
}
library(dplyr)
ozone %>% order_by(ozone)
library(ElemStatLearn);data(ozone,package = "ElemStatLearn")
ozone <- ozone[order(ozone$ozone),]
head(ozone)
ll <- matrix(NA,nrow = 10,ncol=155)
for(i in 1:10){
ss <- sample(1:dim(ozone)[1],replace = T)
ozone0 <- ozone[ss,];ozone0 <-ozone0[order(ozone0$ozone),]
loess0 <- loess(temperature ~ ozone,data=ozone0,span=0.2)
ll[i,] <- predict(loess0,newdata=data.frame(ozone=1:155))
}
ozone %>% order_by(ozone)
order_by(ozone,ozone$ozone)
ozone %>% arrange(ozone)
g <- ggplot(ozone,aes(x=ozone,y=temperature)) + geom_point()
library(ggplot2)
g <- ggplot(ozone,aes(x=ozone,y=temperature)) + geom_point()
for(i in 1:10){
g <- g +geom_line(ll[i,],col="grey",lwd=2)
}
library(ggplot2)
g <- ggplot(ozone,aes(x=ozone,y=temperature)) + geom_point()
for(i in 1:10){
g <- g +geom_line(aes(y=ll[i,],col="grey"),lwd=2)
}
g
dim(ozone)
dim(ozone)
dim(ozone)
dim(ozone)
dim(ozone)
dim(ozone)
dim(ozone)
dim(ozone)
dim(ozone)
dim(ozone)
dim(ozone)
dim(ll)
plot(ozone$ozone,ozone$temperature,pch=19,cex=0.5)
plot(ozone$ozone,ozone$temperature,pch=19,cex=0.5)
for(i in 1:10){lines(1:155,ll[i,],col="grey",lwd=2)}
library(ggplot2)
g <- ggplot(ozone,aes(x=ozone,y=temperature)) + geom_point()
for(i in 1:10){
g <- g +geom_line(aes(x=1:155,y=ll[i,],col="grey"),lwd=2)
}
g
ll
?apply(array, margin, ...)
dim*ll
dim(ll)
library(ggplot2)
plot(ozone$ozone,ozone$temperature,pch=19,cex=0.5)
for(i in 1:10){lines(1:155,ll[i,],col="grey",lwd=2)}
lines(1:155,apply(ll,2,mean),col="red",lwd=2)
apply(ll,2,mean)
predictors <- data.frame(ozone=ozone$ozone)
temperature <- ozone$temperature
treebag <- bag(predictors,temperature,B=10,
bagControl=bagControl(fit=ctreeBag$fit,predict = ctreeBag$pred,
aggregate = ctreeBag$aggregate))
library(caret)
predictors <- data.frame(ozone=ozone$ozone)
temperature <- ozone$temperature
treebag <- bag(predictors,temperature,B=10,
bagControl=bagControl(fit=ctreeBag$fit,predict = ctreeBag$pred,
aggregate = ctreeBag$aggregate))
install.packages("party")
library(caret)
predictors <- data.frame(ozone=ozone$ozone)
temperature <- ozone$temperature
treebag <- bag(predictors,temperature,B=10,
bagControl=bagControl(fit=ctreeBag$fit,predict = ctreeBag$pred,
aggregate = ctreeBag$aggregate))
plot(ozone$ozone,temperature,col="lightgrey",pch=19)
points(ozone$ozone,predict(treebag$fits[[1]]$fit,predictors),pch=19,col="red")
points(ozone$ozone,predict(treebag,predictors),pch=19,col="blue")
data("iris");library(ggpplot)
data("iris");library(ggplot)
data("iris");library(ggplot2)
inTrain <- createDataPartition(y=iris$Species,p=0.7,list=F)
training <- iris[inTrain,]
testing <- iris[-inTrain,]
modFit <- train(Species ~.,data=training,method="rf",prox=T)
modFit
data("iris");library(ggplot2)
inTrain <- createDataPartition(y=iris$Species,p=0.7,list=F)
training <- iris[inTrain,]
testing <- iris[-inTrain,]
modFit <- train(Species ~.,data=training,method="rf",prox=T)
modFit
library(randomForest)
getTree(modFit$finalModel,k=2)
library(randomForest)
getTree(modFit$finalModel,k=2)
irisP <- classCenter(training[,c(3,4)],training$Species,modFit$finalModel$prox)
irisP <- as.data.frame(irisP)
irisP$Species <-rownames(irisP)
irisP <- classCenter(training[,c(3,4)],training$Species,modFit$finalModel$prox)
irisP <- as.data.frame(irisP);
irisP$Species <-rownames(irisP)
p <- qplot(Petal.Width,Petal.Length,col=Species,data=training)
p + geom_point(aes(x=Petal.Width,y=Petal.Length,col=Species),size=5,shape=4,data=irisP)
?classCenter
irisP <- classCenter(training[,c(3,4)],training$Species,modFit$finalModel$prox)
irisP
irisP <- as.data.frame(irisP);
irisP$Species <-rownames(irisP)
p <- qplot(Petal.Width,Petal.Length,col=Species,data=training)
p + geom_point(aes(x=Petal.Width,y=Petal.Length,col=Species),size=5,shape=4,data=irisP)
pred <- predict(modFit,testing)
testing$predRight <- pred==testing$Species
table(pred,testing$Species)
qplot(Petal.Width,Petal.Length,colour=predRight,data = testing,main="newdata Pred")
library(ISLR);data(Wage);library(ggplot2);library(caret)
Wage <- subset(Wage,select=-c(logwage))
inTrain <- createDataPartition(y=Wage$wage,p=0.7,list=F)
training <- Wage[inTrain,];testing <- Wage[-inTrain,]
modFit <- train(wage~.,method="gbm",data = training,verbose=F)
print(modeFit)
print(modelFit)
print(modFit)
library(AppliedPredictiveModeling)
data(segmentationOriginal)
library(caret)
library(AppliedPredictiveModeling)
data(segmentationOriginal)
library(caret)
head(segmentationOriginal)
set.seed(125)
inTrain <- createDataPartition(segmentationOriginal$Case,p=0.7,list = F)
training <- segmentationOriginal[inTrain,]
testing <- segmentationOriginal[-inTrain,]
modFit <- train(Case~.,method="rpart",data=training)
d1 <- data.frame(TotalIntench2 = 23,000,FiberWidthCh1 = 10,PerimStatusCh1=2)
predict(modFit,d1)
d1
predict(modFit,testing)
set.seed(125)
inTrain <- createDataPartition(segmentationOriginal$Case,p=0.7,list = F)
training <- segmentationOriginal[inTrain,]
testing <- segmentationOriginal[-inTrain,]
modFit <- train(Case~.,method="rpart",data=training)
print(modFit)
head(training)
set.seed(125)
inTrain <- createDataPartition(segmentationOriginal$Case,p=0.7,list = F)
training <- segmentationOriginal[inTrain,]
testing <- segmentationOriginal[-inTrain,]
modFit <- train(Class~.,method="rpart",data=training)
d1 <- data.frame(TotalIntench2 = 23,000,FiberWidthCh1 = 10,PerimStatusCh1=2)
predict(modFit,testing)
d2 <- data.frame(TotalIntench2 = 50,000, FiberWidthCh1 = 10,VarIntenCh4 = 100)
predict(modFit,d2)
library(rattle)
fancyRpartPlot(modFit$finalModel)
# 1. Subset the data to a training set and testing set based on the Case variable in the data set.
inTrain <- createDataPartition(y = segmentationOriginal$Case, p = 0.6,
list = FALSE) # 60% training
training <- segmentationOriginal[inTrain, ]
testing <- segmentationOriginal[-inTrain, ]
# 2. Set the seed to 125 and fit a CART model with the rpart method using all predictor variables and default caret settings. (The outcome class is contained in a factor variable called Class with levels "PS" for poorly segmented and "WS" for well segmented.)
set.seed(125)
modFit <- train(Class ~ ., method = "rpart", data = training)
suppressMessages(library(rattle))
library(rpart.plot)
fancyRpartPlot(modFit$finalModel)
library(AppliedPredictiveModeling)
data(segmentationOriginal)
library(caret)
set.seed(125)
inTrain <- createDataPartition(segmentationOriginal$Case,p=0.6,list = F)
training <- segmentationOriginal[inTrain,]
testing <- segmentationOriginal[-inTrain,]
modFit <- train(Class~.,method="rpart",data=training)
library(rattle)
fancyRpartPlot(modFit$finalModel)
install.packages("pgmm")
download.file("https://d396qusza40orc.cloudfront.net/predmachlearn/data/olive_data.zip",destfile = "olive_data.zip")
unzip("olive_data.zip")
setwd("F:/Coursera/DataScienceSpecializationCoursera/8_Practical_MachineLearning/Week3")
load("olive.rda")
head(olive)
download.file("https://d396qusza40orc.cloudfront.net/predmachlearn/data/olive_data.zip",destfile = "olive_data.zip")
unzip("olive_data.zip")
load("olive.rda")
modFit <- train(Area~.,method="rpart",data=olive)
modFit <- train(Area~.,method="rpart",data=olive)
download.file("https://d396qusza40orc.cloudfront.net/predmachlearn/data/olive_data.zip",destfile = "olive_data.zip")
unzip("olive_data.zip")
load("olive.rda")
modFit <- train(Area~.,method="rpart",data=olive)
newdata = as.data.frame(t(colMeans(olive)))
predict(modFit,newdata = newdata)
newdata$Area
newdata
fancyRpartPlot(olive_rpart$finalModel)
fancyRpartPlot(modFit$finalModel)
library(ElemStatLearn)
data(SAheart)
set.seed(8484)
train = sample(1:dim(SAheart)[1],size=dim(SAheart)[1]/2,replace=F)
head(train)
trainSA = SAheart[train,]
head(trainSA)
trainSA = SAheart[train,]
testSA = SAheart[-train,]
library(ElemStatLearn)
data(SAheart)
set.seed(8484)
train = sample(1:dim(SAheart)[1],size=dim(SAheart)[1]/2,replace=F)
trainSA = SAheart[train,]
testSA = SAheart[-train,]
missClass = function(values,prediction){sum(((prediction > 0.5)*1) != values)/length(values)}
set.seed(13234)
modFit <- train(chd~age+alcohol+obesity+tobacco+typea+ldl,method="glm",
family="binomial")
library(ElemStatLearn)
data(SAheart)
set.seed(8484)
train = sample(1:dim(SAheart)[1],size=dim(SAheart)[1]/2,replace=F)
trainSA = SAheart[train,]
testSA = SAheart[-train,]
missClass = function(values,prediction){sum(((prediction > 0.5)*1) != values)/length(values)}
set.seed(13234)
modFit <- train(chd~age+alcohol+obesity+tobacco+typea+ldl,method="glm",
family="binomial",data=trainSA)
missClass(trainSA$chd,predict(modFit,trainSA))
missClass(testSA$chd,predict(modFit,testSA))
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
library(randomForest)
modFit <- randomForest(y~.,data = vowel.train)
library(ElemStatLearn)
library(randomForest)
data(vowel.train)
data(vowel.test)
vowel.test$y = factor(vowel.test$y)
vowel.train$y = factor(vowel.train$y)
set.seed(33833)
modFit <- randomForest(y~.,data = vowel.train)
varImp(modFit)
sort(importance)
library(ElemStatLearn)
library(randomForest)
data(vowel.train)
data(vowel.test)
vowel.test$y = factor(vowel.test$y)
vowel.train$y = factor(vowel.train$y)
set.seed(33833)
modFit <- randomForest(y~.,data = vowel.train)
importance <-varImp(modFit)
sort(importance)
importance <-varImp(modFit)
importance
typeof
class(importance)
order(importance$Overall)
library(ElemStatLearn)
library(randomForest)
data(vowel.train)
data(vowel.test)
vowel.test$y = factor(vowel.test$y)
vowel.train$y = factor(vowel.train$y)
set.seed(33833)
modFit <- randomForest(y~.,data = vowel.train)
importance <-varImp(modFit)
importance[order(importance$Overall),]
order_by(importance,overall)
order_by(importance,desc(overall))
arrange(importance,overall)
arrange(importance,Overall)
library(ElemStatLearn)
library(randomForest)
data(vowel.train)
data(vowel.test)
vowel.test$y = factor(vowel.test$y)
vowel.train$y = factor(vowel.train$y)
set.seed(33833)
modFit <- randomForest(y~.,data = vowel.train)
importance <-varImp(modFit)
importance$var <- row.names(importance)
arrange(importance,Overall)
arrange(importance,desc(Overall))
