---
title: "Week2"
author: "Naqeeb Asif"
date: "9 February 2018"
output: html_document
---

#Week2

## Spam Example

### Data splitting
```{r,message=F}
library(caret)
library(kernlab)
data(spam)
inTrain <- createDataPartition(y=spam$type,p=0.75,list = FALSE)
training <- spam[inTrain,]
testing <- spam[-inTrain,]
dim(training)
dim(testing)
```

### Fit a model

```{r message=FALSE}
set.seed(32343)
modelFit <- train(type~.,data=training,method="glm")
modelFit
```

### Final model

```{r message=FALSE}
modelFit <- train(type~.,data=training,method="glm")
modelFit$finalModel
```

### Prediction

```{r}
predictions <- predict(modelFit,newdata=testing)
predictions
```

### Confusion Matrix

```{r message=FALSE}
confusionMatrix(predictions,testing$type)

```

### K-folds
#### train
```{r}
set.seed(32323)
folds <- createFolds(y=spam$type,returnTrain = T)
sapply(folds, length)
```

###Test
```{r message=FALSE}
set.seed(32323)
folds <- createFolds(y=spam$type,returnTrain = TRUE)
sapply(folds, length)
```

### Resampling

```{r message=TRUE}
set.seed(32323)
folds <- createResample(y=spam$type,times = 10,
                        list=TRUE)
sapply(folds, length)
```

```{r}
folds[[1]][1:10]
```

## Time Slices

```{r}
set.seed(32323)
tme <- 1:1000
folds <- createTimeSlices(y=tme,initialWindow = 20,
                          horizon = 10)
names(folds)
```

```{r}
folds$train[[1]]
```

```{r}
folds$test[[1]]
```
## Training Options
```{r,message=FALSE}
library(caret)
library(kernlab)
data(spam)
inTrain <- createDataPartition(y=spam$type,p=0.75,list = FALSE)
training <- spam[inTrain,]
testing>-spam[-inTrain,]
modelFit <- train(type~.,data = training,method="glm")
```

# Plotting the predictors

## Example Wage data

```{r}

library(ISLR);library(ggplot2);library(caret)
data("Wage")
summary(Wage)
```

### Get training/test sets

```{r message=FALSE}
inTrain <- createDataPartition(Wage$wage,p=0.7,list = FALSE)
training <- Wage[inTrain,]
testing <- Wage[-inTrain,]
dim(training);dim(testing)
```

### Feature plot(Caret package)

```{r}
featurePlot(x=training[,c("age","education","jobclass")],
            y=training$wage,plot = "pairs")
```

### Explore using ggplot

```{r}
g <- ggplot(data=Wage,aes(y=wage,x=age))
g + geom_point()
```

```{r}
g <- ggplot(data=Wage,aes(y=wage,x=age,colour=jobclass))
g + geom_point()
```
```{r message=FALSE}

library('Hmisc')
cutWage <- cut2(training$wage,g=3)
table(cutWage)
p <- ggplot(data=training,aes(y=age,x=cutWage,fill=cutWage))+ geom_boxplot()
p
```
```{r message=FALSE}
library(gridExtra)
p2 <-p + geom_jitter()
grid.arrange(p,p2,ncol=2)
```

###Tables

```{r message=FALSE}
t1 <- table(cutWage,training$jobclass)
t1
```
```{r}
prop.table(t1,1)
```

###Density plots

```{r}

g <- ggplot(data = Wage,aes(x=wage,colour=education))
g +geom_density()
```

# Basic Preprocessing

## Why preprocess?

```{r message-FALSE}
library(caret)
library(kernlab)
library(ggplot2)
data(spam)
inTrain <- createDataPartition(spam$type,p=0.7,list = FALSE)
training <- spam[inTrain,]
testing <- spam[-inTrain,]
g <- ggplot(data=training,aes(x=capitalAve))+xlab("ave. capital run length") 
g + geom_histogram()
```

```{r message=FALSE}
mean(training$capitalAve)
```
```{r message=FALSE}
sd(training$capitalAve)
```

## Standardizing Training set

```{r}
trainCapAve <- training$capitalAve
trainCapAveS <- (trainCapAve - mean(trainCapAve))/sd(trainCapAve)
mean(trainCapAveS)
```

```{r}
sd(trainCapAveS)
```

## Standardizing test set
```{r}
testCapAve <- testing$capitalAve
testCapAveS <- (testCapAve - mean(trainCapAve))/sd(trainCapAve)
mean(testCapAveS)
```

```{r}
sd(testCapAveS)
```

## Standardizing Preprocessfunction

### Training
```{r}
preObj <- preProcess(training[,-58],method = c("center","scale"))
trainCapAveS <- predict(preObj,training[,-58])$capitalAve
mean(trainCapAveS)
```

```{r}
sd(trainCapAveS)
```

### Testing

```{r}
testCapAveS <- predict(preObj,testing[,-58])$capitalAve
mean(testCapAveS)
```

```{r}
sd(testCapAveS)
```

## Standardizing - Box-Cox transforms

```{r}
library(gridExtra)
preObj <- preProcess(training[,-58],method = c("BoxCox"))
trainCapAveS <- predict(preObj,training[,-58])$capitalAve
g <- ggplot(data=data.frame(trainCapAveS=trainCapAveS))
g1 <- g+geom_histogram(aes(x=trainCapAveS)) + labs(title="Histogram")
g2 <- g+geom_qq(aes(sample=trainCapAveS)) + labs(title="Normal Q-Q Plot")
grid.arrange(g1,g2,ncol=2)

```

## Standardizing - Imputing data

```{r}
set.seed(13343)

# Make some values NA
training$capAve <- training$capitalAve
selectNa <- rbinom(dim(training)[1],size=1,prob = 0.05)==1
training$capAve[selectNa] <- NA

# Impute and standardize
preObj <- preProcess(training[,-58],method = "knnImpute")
capAve <- predict(preObj,training[,-58])$capAve

#Standardize true values
capAveTruth <- training$capitalAve
capAveTruth <- (capAveTruth-mean(capAveTruth))/sd(capAveTruth)
```

# Covariate creatiion

## Transforming tidy covariates
```{r}
library(kernlab);data("spam")
spam$capitalAveSq <- spam$capitalAve^2

```
## Dummy variables
```{r}
library(ISLR)
library(caret)

data(Wage)
inTrain <- createDataPartition(Wage$wage,p = 0.75,list = FALSE)
training <- Wage[inTrain,]
testing <- Wage[-inTrain,]
table(training$jobclass)
```

```{r}
dummies <- dummyVars(wage~jobclass,data=training)
head(predict(dummies,newdata=training))
```

## Removing zero covariates
```{r}
nsv <- nearZeroVar(training,saveMetrics = TRUE)
nsv
```

## Spline basis

```{r}
library(splines)
bsBasis <- bs(training$age,df=3)
bsBasis
```

## Fitting curves with splines

```{r}
lm1 <- lm(wage ~ bsBasis,data = training)
g <- ggplot(data=training,aes(x=age,y=wage))
g + geom_point() +geom_line(aes(y=predict(lm1,new_data=training)),col="red",size=2)
```

## Splines on the test set

```{r}
predict(bsBasis,age=testing$age)
```

#Preprocessing with PCA

## Correlated predictions
```{r}
library(caret);library(kernlab);data(spam)
inTrain <- createDataPartition(spam$type,p=0.75,list=FALSE)

training <- spam[inTrain,]
testing <- spam[-inTrain,]

M <- abs(cor(training[,-58]))
diag(M) <- 0
which(M>0.8,arr.ind = T)
```

```{r}
names(spam)[c(34,32)]
```

```{r}
g <- ggplot(data=training,aes(x=num415,y=num857))
g +geom_point()
```


## Rotate the plot
```{r}
X <- 0.71 *training$num415 +0.71*training$num857
Y <- 0.71 *training$num415 -0.71*training$num857
ggplot(data=data.frame(x=X,y=Y),aes(x=x,y=y)) +geom_point()
```

## Principal Components
```{r}
smallSpam <- spam[,c(34,32)]
prComp <- prcomp(smallSpam)
ggplot(data=data.frame(prComp$x),aes(x=PC1,y=PC2))+geom_point()
```

## Rotation
```{r}
prComp$rotation
```

## PCA on spam data
```{r}
prComp <- prcomp(log(spam[,-58]+1))
ggplot(data=data.frame(prComp$x),
       aes(x=PC1,y=PC2,colour=spam$type)) +
  geom_point()
```

## PCA with caret
```{r}
preProc <- preProcess(log10(spam[,-58]+1),method = "pca",pcaComp = 2)
spamPC <- predict(preProc,log10((spam[,-58]+1)))
ggplot(data = data.frame(spamPC),aes(x=PC1,y=PC2,colour=spam$type))+geom_point()
```

## Preprocessing with PCA

```{r}
preProc <- preProcess(log10(training[,-58]+1),method = "pca",pcaComp = 2)
trainPC <- predict(preProc,log10(training[,-58]+1))
trainPC$type <- training$type
modelFit <- train(type ~. ,method="glm",data=trainPC)
```

```{r}
testPC <- predict(preProc,log10(testing[,-58]+1))
confusionMatrix(testing$type,predict(modelFit,testPC))

```

##Alternative
```{r}
modelFit <- train(type~.,method="glm",preProcess="pca",data=training)
confusionMatrix(testing$type,predict(modelFit,testing))
```

# Predicting with Regression

## Old Faithful erruptions
```{r}
library(caret);data("faithful");set.seed(333)
inTrain <- createDataPartition(y=faithful$waiting,
                               p=0.5,list=FALSE)
trainFaith <- faithful[inTrain,];testFaith <- faithful[-inTrain,]
head(trainFaith)
```
### Eruption duration versus waiting time
```{r}
g <- ggplot(data=trainFaith, aes(x=waiting,y=eruptions))
g + geom_point() + geom_smooth(method = "lm",se = FALSE)
```

### Fit a linera model

```{r}
lm1 <- lm(eruptions~waiting,data=trainFaith)
summary(lm1)
```
###Predict a new value
```{r}
newdata <- data.frame(waiting=80)
predict(lm1,newdata)
```

### Plot Predictions

```{r}
library(gridExtra)
g1 <- ggplot(data=trainFaith,aes(x=waiting,y=eruptions))+geom_point(colour='blue')+
  geom_line(aes(y=predict(lm1,trainFaith)))

g2 <- ggplot(data=testFaith,aes(x=waiting,y=eruptions))+geom_point(colour='blue')+
  geom_line(aes(y=predict(lm1,testFaith)))

grid.arrange(g1,g2,ncol=2)
```

### Errors

```{r}
RMSE(predict(lm1,trainFaith),trainFaith$eruptions)
RMSE(predict(lm1,testFaith),testFaith$eruptions)
```

## Prediction intervals

```{r}
pred1 <- predict(lm1,newdata=testFaith,interval="prediction")
ord <- order(testFaith$waiting)
plot(testFaith$waiting,testFaith$eruptions,pch=19,col="blue")
matlines(testFaith$waiting[ord],pred1[ord,])
```

## Sampe process with caret

```{r}
modelFit <- train(eruptions~waiting,method="lm",data=trainFaith)
summary(modelFit$finalModel)
```

# Multiplie Linear Regression

## Wage Data
```{r}
library(ISLR);library(ggplot2);library(caret);library(dplyr)
data(Wage);
Wage <- select(Wage,-logwage)
summary(Wage)
```

## Splitting
```{r}
inTrain <- createDataPartition(y=Wage$wage,p=0.7,list = F)
training <- Wage[inTrain,];testing<- Wage[-inTrain,]
dim(training);dim(testing)
```

##Feature plot
```{r}
featurePlot(x=training[,c("age","education","jobclass")],
            y=training$wage,
            plot = "pairs")
```

##Plot age versus wage

```{r}
g <- ggplot(data = training,aes(y=wage,x=age))
g +geom_point()
```

## Plot age versus wage colour by jobclass

```{r}
g + geom_point(aes(colour=jobclass))
```

## Plot age versus wage colour by education

```{r}
g + geom_point(aes(colour=education))
```


### Fit a linear model

```{r}
modelFit<- train(wage~age+education+jobclass,method="lm",data=training)
fitMod <- modelFit$finalModel
print(fitMod)
```

###Color by values not used in model

```{r}
g<- ggplot(data=training,aes(x=fitMod$fitted.values,y=fitMod$residuals,
                             colour=region)) 
g +geom_point()
```

### Predicted versus truth in test results

```{r}
pred <- predict(modelFit,testing)
g <- ggplot(data=testing,aes(x=wage,y=pred,colour=year))
g+geom_point()
```

#Quiz2

#Q2
```{r}
library(AppliedPredictiveModeling)
data(concrete)
library(caret)
set.seed(1000)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
```

```{r}
library(ggplot2)
library(Hmisc)
library(rlist)
createPlotByColour <- function(data,colour,pred=NA,title){
  if(is.na(pred)){
    pred <- 1:dim(data)[1]
  }
  g <- ggplot(data=data,aes(x=pred,y=CompressiveStrength,colour=colour))+
    geom_point() + labs(title=title)
  g
}
g_plots_list <- list()

for(i in 1:8){
  colour <- cut2(training[,i],g=4)
  g <- createPlotByColour(training,"",colour=colour ,title=colnames(training)[i])
  g_plots_list<-list.append(g_plots_list,g)
}

grid.arrange(grobs=g_plots_list,ncol=2)
```

#Q3

```{r}
library(AppliedPredictiveModeling)
data(concrete)
library(caret)
set.seed(1000)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
qplot(Superplasticizer,data = training)
```
```{r}
qplot(log10(Superplasticizer+1),data = training)
```

# Q4
```{r}
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
trainingIL <- training[,grep("^IL", names(training))]
procTrain <- preProcess(trainingIL, method = "pca", thresh = 0.9 )
procTrain

```

# Q5
```{r}
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]


trainingIL <- training[,grep("^IL|diagnosis", names(training))]
testingIL <- testing[,grep("^IL|diagnosis", names(testing))]

model_notPC <- train(diagnosis ~.,method="glm",data=trainingIL)
mat <-confusionMatrix(testingIL$diagnosis,predict(model_notPC,newdata=testingIL))
mat$overall[1]
```

```{r}
ctrl <- trainControl(preProcOptions = list(thresh = 0.8))
model_notPC <- train(diagnosis ~.,method="glm",preProcess="pca",trControl=ctrl,data=trainingIL)

confusionMatrix(testingIL$diagnosis,predict(model_notPC,testingIL))

```